# Hand Landmark Analysis for Alphabet Gesture Interpretation

## ğŸš€ Project Overview

This project created a real-time system that translates hand signs (A-Z) into text. It's designed to help individuals with hearing and speech impairments communicate more easily using gestures.

## âœ¨ Key Features

* **Real-time Gesture Recognition:** Detects hand signs for the English alphabet instantly.
* **Assistive Technology:** Provides a visual aid for communication.
* **Core AI Skills:** Uses Computer Vision and Machine Learning (Random Forest) for hand landmark analysis.

## ğŸ› ï¸ Technologies

* Python
* MediaPipe
* OpenCV
* scikit-learn
## ğŸ“ˆ Demo

Here are screenshots of the final output:

**Screenshot of Letter A:**
<img src="https://raw.githubusercontent.com/zuveriya-shaik/Sign_Language_Detection/master/assests/Letter%20-%20A.jpg" alt="Hand Gesture for Letter A" width="300"/>

**Screenshot of Letter U:**
<img src="https://raw.githubusercontent.com/zuveriya-shaik/Sign_Language_Detection/master/assests/Letter%20-%20U.jpg" alt="Hand Gesture for Letter U" width="300"/>

**Screenshot of Number 9:**
<img src="https://raw.githubusercontent.com/zuveriya-shaik/Sign_Language_Detection/master/assests/Number%20-%209.jpg" alt="Hand Gesture for Number 9" width="300"/>
